{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hC55KIJ-sKXS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"IMDB Dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "W_hDhRoUsKXT"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'<.*?>','',text)\n",
        "    text = re.sub(r'[^a-zA-Z\\s]','',text)\n",
        "    text = text.lower()\n",
        "    return text\n",
        "data['review']= data['review'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GbH4Dw0sKXT",
        "outputId": "77ee60c4-e313-47ad-8911-393bced02f96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review sentiment\n",
            "0  one of the other reviewers has mentioned that ...  positive\n",
            "1  a wonderful little production the filming tech...  positive\n",
            "2  i thought this was a wonderful way to spend ti...  positive\n",
            "3  basically theres a family where a little boy j...  negative\n",
            "4  petter matteis love in the time of money is a ...  positive\n"
          ]
        }
      ],
      "source": [
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TP360ai4sKXU",
        "outputId": "5b93241c-d131-4b6c-f2f8-ce9465b2463e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"
          ]
        }
      ],
      "source": [
        "pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIBJ1nDLsKXU",
        "outputId": "8fb3f147-3df5-4ed9-e4b4-972632ff9bf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# downloading stop-words from NLTK\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    words = text.split()\n",
        "    words = [ word for word in words if word not in stop_words]\n",
        "    words = [stemmer.stem(word) for word in words]\n",
        "    return ' '.join(words)\n",
        "\n",
        "data['review'] = data['review'].apply(preprocess_text)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xQurZ0G2sKXU"
      },
      "outputs": [],
      "source": [
        "data['sentiment'] = data['sentiment'].map({'positive':1,'negative':0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwOpamVHsKXU",
        "outputId": "d724470c-81e1-48d8-9de5-8406490c2f89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review  sentiment\n",
            "0  one review mention watch oz episod youll hook ...          1\n",
            "1  wonder littl product film techniqu unassum old...          1\n",
            "2  thought wonder way spend time hot summer weeke...          1\n",
            "3  basic there famili littl boy jake think there ...          0\n",
            "4  petter mattei love time money visual stun film...          1\n"
          ]
        }
      ],
      "source": [
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RF-2lV7PsKXU",
        "outputId": "ad99544d-5389-4332-e5c5-9524726de923"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "review       0\n",
            "sentiment    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(data.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VAMAJ9hsKXV",
        "outputId": "7fefeff1-f265-43a6-fd2a-ea981203a5c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentiment\n",
            "1    25000\n",
            "0    25000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(data['sentiment'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nJd-am0sKXV",
        "outputId": "50fb8d7c-cb77-4e6c-ee9c-dcce4ceced0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "pip install -U scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UayS-t92sKXV",
        "outputId": "4039487a-7c9f-4fd4-e85d-d6d48c8f79af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training data set40000\n",
            "testing data set10000\n"
          ]
        }
      ],
      "source": [
        "#Preparing data and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = data['review']\n",
        "y = data['sentiment']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
        "\n",
        "print(f\"training data set{len(X_train)}\")\n",
        "\n",
        "print(f\"testing data set{len(y_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oc95BfuWsKXV",
        "outputId": "fe69373b-8b54-4e77-fa90-86463870fc02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train review data examples: \n",
            "39087    that kept ask mani fight scream match swear ge...\n",
            "30893    watch entir movi could watch entir movi stop d...\n",
            "45278    touch love stori reminisc mood love draw heavi...\n",
            "16398    latterday fulci schlocker total abysm concoct ...\n",
            "13653    first firmli believ norwegian movi continu get...\n",
            "Name: review, dtype: object\n",
            "train sentiment data examples: \n",
            "39087    0\n",
            "30893    0\n",
            "45278    1\n",
            "16398    0\n",
            "13653    0\n",
            "Name: sentiment, dtype: int64\n",
            "test review data examples: \n",
            "33553    realli like summerslam due look arena curtain ...\n",
            "9427     mani televis show appeal quit mani differ kind...\n",
            "199      film quickli get major chase scene ever increa...\n",
            "12447    jane austen would definit approv onegwyneth pa...\n",
            "39489    expect somewhat high went see movi thought ste...\n",
            "Name: review, dtype: object\n",
            "test sentiment data examples: \n",
            "33553    1\n",
            "9427     1\n",
            "199      0\n",
            "12447    1\n",
            "39489    0\n",
            "Name: sentiment, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(f\"train review data examples: \\n{X_train.head(5)}\")\n",
        "print(f\"train sentiment data examples: \\n{y_train.head(5)}\")\n",
        "print(f\"test review data examples: \\n{X_test.head(5)}\")\n",
        "print(f\"test sentiment data examples: \\n{y_test.head(5)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "oFGInJqfsKXV"
      },
      "outputs": [],
      "source": [
        "# Vectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=5000,stop_words='english')\n",
        "\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynJiVAXlyZxI",
        "outputId": "9fae9b5e-7fd8-495b-c545-a1d8adc7cdfc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.7.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RBlC-Rvrzcjx",
        "outputId": "a907369b-a9d3-4e67-c214-57588983f068"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-gpu\n",
            "  Using cached tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense, Dropout\n",
        "# from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# # Model tanımlama\n",
        "# model = Sequential([\n",
        "#     Dense(128, input_dim=X_train_tfidf.shape[1], activation='relu'),\n",
        "#     Dropout(0.5),\n",
        "#     Dense(64, activation='relu'),\n",
        "#     Dense(1, activation='sigmoid')\n",
        "# ])\n",
        "\n",
        "# # Modeli derleme (bu kısım eksik kalmış)\n",
        "# model.compile(\n",
        "#     optimizer='adam',\n",
        "#     loss='binary_crossentropy',\n",
        "#     metrics=['accuracy']\n",
        "# )\n",
        "\n",
        "# # Early stopping ve learning rate ayarı\n",
        "# early_stopping = EarlyStopping(\n",
        "#     monitor='val_loss',\n",
        "#     patience=3,\n",
        "#     restore_best_weights=True\n",
        "# )\n",
        "\n",
        "# reduce_lr = ReduceLROnPlateau(\n",
        "#     monitor='val_loss',\n",
        "#     factor=0.2,\n",
        "#     patience=2,\n",
        "#     min_lr=0.0001\n",
        "# )\n",
        "\n",
        "# # Model eğitimi\n",
        "# history = model.fit(\n",
        "#     X_train_tfidf, y_train,\n",
        "#     epochs=5,\n",
        "#     batch_size=128,\n",
        "#     validation_data=(X_test_tfidf, y_test),\n",
        "#     callbacks=[early_stopping, reduce_lr]\n",
        "# )\n",
        "\n",
        "# # Modeli değerlendirme\n",
        "# loss, accuracy = model.evaluate(X_test_tfidf, y_test)\n",
        "# print(f\"Test Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "s4jJU8VVzcd6",
        "outputId": "d94f8ef2-f73d-4573-f8e0-222ec1d518d2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m384s\u001b[0m 1s/step - accuracy: 0.7773 - loss: 0.4779 - val_accuracy: 0.8792 - val_loss: 0.2775 - learning_rate: 0.0010\n",
            "Epoch 2/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 954ms/step - accuracy: 0.9052 - loss: 0.2357 - val_accuracy: 0.8774 - val_loss: 0.2857 - learning_rate: 0.0010\n",
            "Epoch 3/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 826ms/step - accuracy: 0.9246 - loss: 0.1979 - val_accuracy: 0.8777 - val_loss: 0.2922 - learning_rate: 0.0010\n",
            "Epoch 4/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 662ms/step - accuracy: 0.9500 - loss: 0.1509 - val_accuracy: 0.8777 - val_loss: 0.3121 - learning_rate: 2.0000e-04\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 256ms/step - accuracy: 0.8786 - loss: 0.2769\n",
            "Test Accuracy: 0.8791999816894531\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, input_dim=X_train_tfidf.shape[1], activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # İkili sınıflandırma için sigmoid\n",
        "])\n",
        "\n",
        "# 4. Modeli derleme\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 5. Modeli eğitme\n",
        "model.fit(X_train_tfidf, y_train, epochs=5, batch_size=128, validation_data=(X_test_tfidf, y_test))\n",
        "\n",
        "# 6. Modeli değerlendirme\n",
        "loss, accuracy = model.evaluate(X_test_tfidf, y_test)\n",
        "print(f\"Test Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "euh7lgRDyMH0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Modeli değerlendirme\n",
        "loss, accuracy = model.evaluate(X_test_tfidf, y_test)\n",
        "print(f\"Test Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yb4-IjXj5fS9",
        "outputId": "f7407d8d-aae7-4bb1-f651-f807a38a8760"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8786 - loss: 0.2769\n",
            "Test Accuracy: 0.8791999816894531\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AE84faY4sKXV",
        "outputId": "e7c9b56c-59cb-4c43-b55e-75677e29549e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 167ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.86      0.88      4961\n",
            "           1       0.87      0.90      0.88      5039\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Tahminleri yap\n",
        "y_pred_proba = model.predict(X_test_tfidf)  # Modelin verdiği olasılık değerleri\n",
        "y_pred = (y_pred_proba >= 0.5).astype(int)  # Olasılıkları binary değerlere dönüştür\n",
        "\n",
        "# Raporu yazdır\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gl2cH6q_sKXV"
      },
      "source": [
        "SAVING TRAINED MODEL AND VECTOIZER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_yAEilN1sKXW"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "model = model\n",
        "\n",
        "with open('model.pkl','wb') as file:\n",
        "    pickle.dump(model,file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Wi_wN3PasKXW"
      },
      "outputs": [],
      "source": [
        "with open('tfidf_vectorizer.pkl', 'wb') as file:\n",
        "    pickle.dump(vectorizer, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXiCdLWusKXW"
      },
      "source": [
        "LOADİNG TRAINED MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Pm6e_dwFsKXW"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('model.pkl','rb') as file :\n",
        "    loaded_model = pickle.load(file)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjCyVj5csKXW",
        "outputId": "d305d5e0-ab37-48cc-c570-4d2a304dee6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 82ms/step\n"
          ]
        }
      ],
      "source": [
        "predictions = loaded_model.predict(X_test_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHedzdRTsKXW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qq9qF8KmsKXW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_8u62Z4sKXW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOm3gh_vsKXW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}